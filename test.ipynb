{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e70fc3df",
   "metadata": {},
   "source": [
    "## BUILDING A QnA App using Graph DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7213713f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db167c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4394b09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.28.2\n",
      "0.5.0\n"
     ]
    }
   ],
   "source": [
    "import neo4j\n",
    "import langchain_neo4j\n",
    "\n",
    "print(neo4j.__version__)\n",
    "print(langchain_neo4j.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d595a83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.graphs.neo4j_graph.Neo4jGraph at 0x28b515122d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URI, \n",
    "    username=NEO4J_USERNAME, \n",
    "    password=NEO4J_PASSWORD\n",
    ")\n",
    "\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6851e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nLOAD CSV WITH HEADERS FROM\\n'https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/movies/movies_small.csv' as row\\n\\nMERGE(m:Movie{id:row.movieId})\\nSET m.released = date(row.released),\\n    m.title = row.title,\\n    m.imdbRating = toFloat(row.imdbRating)\\nFOREACH (director in split(row.director, '|') | \\n    MERGE (p:Person {name:trim(director)})\\n    MERGE (p)-[:DIRECTED]->(m))\\nFOREACH (actor in split(row.actors, '|') | \\n    MERGE (p:Person {name:trim(actor)})\\n    MERGE (p)-[:ACTED_IN]->(m))\\nFOREACH (genre in split(row.genres, '|') | \\n    MERGE (g:Genre {name:trim(genre)})\\n    MERGE (m)-[:IN_GENRE]->(g))\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dataset Movie\n",
    "movie_query=\"\"\"\n",
    "LOAD CSV WITH HEADERS FROM\n",
    "'https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/movies/movies_small.csv' as row\n",
    "\n",
    "MERGE(m:Movie{id:row.movieId})\n",
    "SET m.released = date(row.released),\n",
    "    m.title = row.title,\n",
    "    m.imdbRating = toFloat(row.imdbRating)\n",
    "FOREACH (director in split(row.director, '|') | \n",
    "    MERGE (p:Person {name:trim(director)})\n",
    "    MERGE (p)-[:DIRECTED]->(m))\n",
    "FOREACH (actor in split(row.actors, '|') | \n",
    "    MERGE (p:Person {name:trim(actor)})\n",
    "    MERGE (p)-[:ACTED_IN]->(m))\n",
    "FOREACH (genre in split(row.genres, '|') | \n",
    "    MERGE (g:Genre {name:trim(genre)})\n",
    "    MERGE (m)-[:IN_GENRE]->(g))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "movie_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e45e8aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(movie_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f3a56fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "Person {name: STRING}\n",
      "Movie {title: STRING, released: DATE, id: STRING, imdbRating: FLOAT}\n",
      "Genre {name: STRING}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:Person)-[:DIRECTED]->(:Movie)\n",
      "(:Person)-[:ACTED_IN]->(:Movie)\n",
      "(:Movie)-[:IN_GENRE]->(:Genre)\n"
     ]
    }
   ],
   "source": [
    "graph.refresh_schema()\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50f56c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b364d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ce90055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000028B52B97FB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000028B529D0CB0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model = \"llama-3.1-8b-instant\",\n",
    "    groq_api_key = groq_api_key\n",
    ")\n",
    "\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "58ee1346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm an artificial intelligence model known as a large language model (LLM) or conversational AI. I'm a computer program designed to understand and generate human-like text responses to a wide range of questions and topics.\\n\\nI don't have a personal identity or emotions, but I'm here to assist and provide information to the best of my abilities. I can:\\n\\n1. Answer questions on various subjects, from science and history to entertainment and culture.\\n2. Provide definitions and explanations of words and concepts.\\n3. Offer suggestions and ideas for creative projects or everyday problems.\\n4. Engage in conversations and discussions on various topics.\\n5. Translate text from one language to another.\\n6. Generate text based on a prompt or topic.\\n\\nI'm constantly learning and improving, so I appreciate any feedback or corrections you can provide to help me become a better conversational AI.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 175, 'prompt_tokens': 40, 'total_tokens': 215, 'completion_time': 0.241842723, 'prompt_time': 0.001846406, 'queue_time': 0.05154327, 'total_time': 0.243689129}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--6516716a-d6e6-42a1-812e-b3d02684c7e8-0', usage_metadata={'input_tokens': 40, 'output_tokens': 175, 'total_tokens': 215})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"WHo are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86d9b791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphCypherQAChain(verbose=True, graph=<langchain_community.graphs.neo4j_graph.Neo4jGraph object at 0x0000028B515122D0>, cypher_generation_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question', 'schema'], input_types={}, partial_variables={}, template='Task:Generate Cypher statement to query a graph database.\\nInstructions:\\nUse only the provided relationship types and properties in the schema.\\nDo not use any other relationship types or properties that are not provided.\\nSchema:\\n{schema}\\nNote: Do not include any explanations or apologies in your responses.\\nDo not respond to any questions that might ask anything else than for you to construct a Cypher statement.\\nDo not include any text except the generated Cypher statement.\\n\\nThe question is:\\n{question}'), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000028B52B97FB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000028B529D0CB0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), qa_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant that helps to form nice and human understandable answers.\\nThe information part contains the provided information that you must use to construct an answer.\\nThe provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\\nMake the answer sound as a response to the question. Do not mention that you based the result on the given information.\\nHere is an example:\\n\\nQuestion: Which managers own Neo4j stocks?\\nContext:[manager:CTL LLC, manager:JANE STREET GROUP LLC]\\nHelpful Answer: CTL LLC, JANE STREET GROUP LLC owns Neo4j stocks.\\n\\nFollow this example when generating answers.\\nIf the provided information is empty, say that you don't know the answer.\\nInformation:\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000028B52B97FB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000028B529D0CB0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), graph_schema='Node properties are the following:\\nPerson {name: STRING},Movie {title: STRING, released: DATE, id: STRING, imdbRating: FLOAT}\\nRelationship properties are the following:\\n\\nThe relationships are the following:\\n(:Person)-[:DIRECTED]->(:Movie),(:Person)-[:ACTED_IN]->(:Movie)', allow_dangerous_requests=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chains.graph_qa.cypher import GraphCypherQAChain\n",
    "\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    graph = graph,\n",
    "    llm = llm,\n",
    "    verbose = True,\n",
    "    allow_dangerous_requests = True,\n",
    "    exclude_types=[\"Genre\"]\n",
    ")\n",
    "\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c1cf733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Person)-[:ACTED_IN]->(m:Movie)<-[:DIRECTED]-(d:Person) WHERE m.title = \"Casino\" RETURN p.name\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'p.name': 'Robert De Niro'}, {'p.name': 'Joe Pesci'}, {'p.name': 'Sharon Stone'}, {'p.name': 'James Woods'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Who are the actors of the movie Casino',\n",
       " 'result': 'Robert De Niro, Joe Pesci, Sharon Stone, James Woods are the actors of the movie Casino.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who are the actors of the movie Casino\"\n",
    "\n",
    "response = chain.invoke({\"query\":query})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1cdfdd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"question\": \"How many artists are there?\",\n",
    "        \"query\": \"MATCH (a:Person)-[:ACTED_IN]->(:Movie) RETURN count(DISTINCT a)\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which actors played in the movie Casino?\",\n",
    "        \"query\": \"MATCH (m:Movie {{title: 'Casino'}})<-[:ACTED_IN]-(a) RETURN a.name\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many movies has Tom Hanks acted in?\",\n",
    "        \"query\": \"MATCH (a:Person {name: 'Tom Hanks'})-[:ACTED_IN]->(m:Movie) RETURN count(m)\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"List all the genres of the movie Schindler's List\",\n",
    "        \"query\": \"MATCH (m:Movie {{title: 'Schindler\\\\'s List'}})-[:IN_GENRE]->(g:Genre) RETURN g.name\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which actors have worked in movies from both the comedy and action genres?\",\n",
    "        \"query\": \"MATCH (a:Person)-[:ACTED_IN]->(:Movie)-[:IN_GENRE]->(g1:Genre), (a)-[:ACTED_IN]->(:Movie)-[:IN_GENRE]->(g2:Genre) WHERE g1.name = 'Comedy' AND g2.name = 'Action' RETURN DISTINCT a.name\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which directors have made movies with at least three different actors named 'John'?\",\n",
    "        \"query\": \"MATCH (d:Person)-[:DIRECTED]->(m:Movie)<-[:ACTED_IN]-(a:Person) WHERE a.name STARTS WITH 'John' WITH d, COUNT(DISTINCT a) AS JohnsCount WHERE JohnsCount >= 3 RETURN d.name\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Identify movies where directors also played a role in the film.\",\n",
    "        \"query\": \"MATCH (p:Person)-[:DIRECTED]->(m:Movie), (p)-[:ACTED_IN]->(m) RETURN m.title, p.name\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find the actor with the highest number of movies in the database.\",\n",
    "        \"query\": \"MATCH (a:Actor)-[:ACTED_IN]->(m:Movie) RETURN a.name, COUNT(m) AS movieCount ORDER BY movieCount DESC LIMIT 1\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "925e6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ex in examples:\n",
    "    ex[\"query\"] = ex[\"query\"].replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f01c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate,PromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\n",
    "    \"User Query: {question} \\n Cypher Query:{query}\"\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples[:5],\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=(\n",
    "        \"You're a Neo4j expert. Given an input question and the database schema below, \"\n",
    "        \"create a syntactically very accurate Cypher query.\\n\\nSchema:\\n{schema}\\n\"\n",
    "    ),\n",
    "    suffix=\"User input: {question}\\nCypher Query:\",\n",
    "    input_variables=[\"question\", \"schema\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86789c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FewShotPromptTemplate(input_variables=['question', 'schema'], input_types={}, partial_variables={}, examples=[{'question': 'How many artists are there?', 'query': 'MATCH (a:Person)-[:ACTED_IN]->(:Movie) RETURN count(DISTINCT a)'}, {'question': 'Which actors played in the movie Casino?', 'query': \"MATCH (m:Movie {{{{title: 'Casino'}}}})<-[:ACTED_IN]-(a) RETURN a.name\"}, {'question': 'How many movies has Tom Hanks acted in?', 'query': \"MATCH (a:Person {{name: 'Tom Hanks'}})-[:ACTED_IN]->(m:Movie) RETURN count(m)\"}, {'question': \"List all the genres of the movie Schindler's List\", 'query': \"MATCH (m:Movie {{{{title: 'Schindler\\\\'s List'}}}})-[:IN_GENRE]->(g:Genre) RETURN g.name\"}, {'question': 'Which actors have worked in movies from both the comedy and action genres?', 'query': \"MATCH (a:Person)-[:ACTED_IN]->(:Movie)-[:IN_GENRE]->(g1:Genre), (a)-[:ACTED_IN]->(:Movie)-[:IN_GENRE]->(g2:Genre) WHERE g1.name = 'Comedy' AND g2.name = 'Action' RETURN DISTINCT a.name\"}], example_prompt=PromptTemplate(input_variables=['query', 'question'], input_types={}, partial_variables={}, template='User Query: {question} \\n Cypher Query:{query}'), suffix='User input: {question}\\nCypher Query:', prefix=\"You're a Neo4j expert. Given an input question and the database schema below, create a syntactically very accurate Cypher query.\\n\\nSchema:\\n{schema}\\n\")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7916957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a Neo4j expert. Given an input question and the database schema below, create a syntactically very accurate Cypher query.\n",
      "\n",
      "Schema:\n",
      "foo\n",
      "\n",
      "\n",
      "User Query: How many artists are there? \n",
      " Cypher Query:MATCH (a:Person)-[:ACTED_IN]->(:Movie) RETURN count(DISTINCT a)\n",
      "\n",
      "User Query: Which actors played in the movie Casino? \n",
      " Cypher Query:MATCH (m:Movie {{title: 'Casino'}})<-[:ACTED_IN]-(a) RETURN a.name\n",
      "\n",
      "User Query: How many movies has Tom Hanks acted in? \n",
      " Cypher Query:MATCH (a:Person {name: 'Tom Hanks'})-[:ACTED_IN]->(m:Movie) RETURN count(m)\n",
      "\n",
      "User Query: List all the genres of the movie Schindler's List \n",
      " Cypher Query:MATCH (m:Movie {{title: 'Schindler\\'s List'}})-[:IN_GENRE]->(g:Genre) RETURN g.name\n",
      "\n",
      "User Query: Which actors have worked in movies from both the comedy and action genres? \n",
      " Cypher Query:MATCH (a:Person)-[:ACTED_IN]->(:Movie)-[:IN_GENRE]->(g1:Genre), (a)-[:ACTED_IN]->(:Movie)-[:IN_GENRE]->(g2:Genre) WHERE g1.name = 'Comedy' AND g2.name = 'Action' RETURN DISTINCT a.name\n",
      "\n",
      "User input: How many artist are there?\n",
      "Cypher Query:\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(question=\"How many artist are there?\", schema = \"foo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46285b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000028B52B97FB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000028B529D0CB0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5940fe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = GraphCypherQAChain.from_llm(\n",
    "    graph = graph,\n",
    "    llm = llm,\n",
    "    cypher_prompt = prompt,\n",
    "    verbose = True,\n",
    "    allow_dangerous_requests = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bf18aa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (a:Person)-[:ACTED_IN]->(m:Movie)\n",
      "RETURN a.name, COUNT(m) AS num_movies\n",
      "ORDER BY num_movies DESC\n",
      "LIMIT 1\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'a.name': 'Gene Hackman', 'num_movies': 4}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Find the actor with the highest number of movies in the database.',\n",
       " 'result': 'Gene Hackman has the highest number of movies in the database with 4 movies.'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Find the actor with the highest number of movies in the database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac55cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
